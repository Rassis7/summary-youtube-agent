{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que são agentes de IA?\n",
    "\n",
    "Um agente de IA é um sistema que decide e executa ações para atingir objetivos, interagindo com usuários, dados e APIs. Combina modelos de linguagem, lógica de controle e ferramentas especializadas para resolver tarefas de forma autônoma.\n",
    "\n",
    "**Principais características:**\n",
    "- **Autonomia:** Seleciona passos sem intervenção constante.  \n",
    "- **Ferramentas (tools):** Chama funções externas (transcrição, busca, BD).  \n",
    "- **Contexto:** Mantém histórico para respostas coerentes.  \n",
    "- **Fluxos (chains):** Encadeia prompts e processa saídas de LLMs.  \n",
    "- **RAG:** Recupera dados externos antes de gerar respostas.\n",
    "\n",
    "**Benefícios:**\n",
    "- Automatiza resumos, buscas e relatórios.  \n",
    "- Integra serviços e APIs num único fluxo.  \n",
    "- Escala atendimentos e análises.  \n",
    "- Facilita criação de chatbots e assistentes virtuais.\n",
    "\n",
    "Em essência, funciona como um orquestrador inteligente que une modelos de linguagem e ferramentas para pipelines dinâmicos e contextuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que nosso agente fará?\n",
    "\n",
    "<img src=\"docs/agent.png\" alt=\"agent\" style=\"width:800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivos\n",
    "\n",
    "- Mostrar como configurar o ambiente e dependências.\n",
    "- Entender o uso de variáveis de ambiente (.env).\n",
    "- Explorar como definimos ferramentas com @tool.\n",
    "- Ver como montamos um agente com LangChain.\n",
    "- Executar o agente em um exemplo prático.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuração do Ambiente\n",
    "\n",
    "### 2.1 Criando e ativando o venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Criando venv\n",
    "python3 -m venv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Ativando venv\n",
    "\n",
    "# No Linux/Mac\n",
    "source venv/bin/activate\n",
    "\n",
    "# No Windows (PowerShell)\n",
    "venv\\Scripts\\Activate.ps1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Instalando dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variáveis de Ambiente (.env)\n",
    "Usamos python-dotenv para carregar configurações sem expor senhas ou chaves no código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Lê o arquivo .env e define variáveis em os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERSATION_MODEL: escolhe o modelo de LLM (ex.: llama2 ou openai).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Importações Principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, logging\n",
    "from typing import List, Optional\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.tools import tool\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# Ajuste de path para módulos locais\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "# Módulos customizados\n",
    "from transcribe import transcribe_youtube_videos\n",
    "from news import search_news\n",
    "from llm import LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principais ferramentas usadas:\n",
    "\n",
    "**[Langchain](https://www.langchain.com/)**\n",
    "\n",
    "LangChain é um framework open‑source para criar aplicações com modelos de linguagem. Oferece abstrações para LLMs, gerenciamento de prompts, cadeias de processamento, agentes, integração com bases de dados e memória, permitindo desenvolver chatbots, sistemas RAG e fluxos complexos de IA de forma modular.\n",
    "\n",
    "**[Ollama](https://ollama.com/)**\n",
    "\n",
    "Ollama é uma plataforma CLI e servidor local para hospedar e executar modelos de linguagem (LLMs). Permite baixar, gerenciar e servir LLMs no próprio hardware, oferecendo API REST e integração com frameworks como LangChain para geração de texto, embeddings e pipelines de RAG sem depender de serviços em nuvem.\n",
    "\n",
    "**LLM usadas**\n",
    "\n",
    "- llama3.1:latest\n",
    "- gpt-3.5-turbo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Definindo Ferramentas (@tool)\n",
    "\n",
    "Cada função marcada com `@tool` vira uma ferramenta que o agente pode chamar.\n",
    "Cada ferramenta deve ter uma **descrição muito bem detalhada** para o agente saber quando e como deve invocar ela.\n",
    "\n",
    "As ferramentas podem e devem executar o que for preciso para concluir seu trabalho, como por exemplo:\n",
    "- Chamar uma API Http\n",
    "- Chamar outra LLM\n",
    "- Salvar arquivos\n",
    "- ETC\n",
    "\n",
    "### 5.1 Transcrição de Vídeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transcribe_tool(url: str) -> str:\n",
    "    \"\"\"\n",
    "    DESCRIPTION HERE...\n",
    "    \"\"\"\n",
    "    # Recebe URL de YouTube, retorna texto transcrito\n",
    "    transcription = transcribe_youtube_videos(url, FILES_FOLDER_PATH)\n",
    "    return transcription or \"I don't know\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Resumo de Transcrição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def summarize_tool(transcription: str) -> str:\n",
    "    \"\"\"\n",
    "    DESCRIPTION HERE...\n",
    "    \"\"\"\n",
    "    # Usa LLM para resumir em bullet points\n",
    "    llm = LLM.load_ollama_model(model_name, temperature=0.5)\n",
    "    messages = [SystemMessage(...), HumanMessage(transcription)]\n",
    "    return llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Busca de Notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_news_tools(text: str, max_results: Optional[int] = None) -> List[dict]:\n",
    "    \"\"\"\n",
    "    DESCRIPTION HERE...\n",
    "    \"\"\"\n",
    "    # Extrai keywords via LLM e busca em API de notícias\n",
    "    keywords = llm.invoke([...])\n",
    "    return search_news(query=keywords, max_results=max_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Salvando Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def save_tool(response: str) -> None:\n",
    "    \"\"\"\n",
    "    DESCRIPTION HERE...\n",
    "    \"\"\"\n",
    "    with open(\"agent_output.md\", \"w\") as f:\n",
    "        f.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Montando o Agente\n",
    "\n",
    "1. Criar a caixa de ferramentas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = [transcribe_tool, summarize_tool, search_news_tools, save_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prompt Template: define a conversa inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente de IA...\"),\n",
    "    MessagesPlaceholder(\"history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Criando o agente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_llm = LLM.load_open_ai_model(temperature=0)\n",
    "agent = create_openai_functions_agent(agent_llm, toolkit, prompt)\n",
    "executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- verbose=True: imprime passo a passo da decisão do agente.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exemplo de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent():\n",
    "    text_input = [\n",
    "        \"Summarize the video at https://...\",\n",
    "        \"Search for 5 news articles...\",\n",
    "        \"Save the summary, keywords and news in pt-BR.\",\n",
    "    ]\n",
    "    result = executor.invoke({\"input\": text_input})\n",
    "    print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O agente vai chamar, em ordem, transcribe_tool, summarize_tool, search_news_tools e save_tool.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fluxo de Dados\n",
    "\n",
    "1. Entrada: URLs e instruções do usuário.\n",
    "2. Ferramentas: transcrição → resumo → busca → gravação.\n",
    "3. Agente: coordena chamadas, decide qual ferramenta usar.\n",
    "4. Saída: arquivo agent_output.md com o resultado final.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusão\n",
    "\n",
    "- Agentes de IA permitem combinar várias capacidades (tools) de forma dinâmica.\n",
    "- O LangChain simplifica registro de ferramentas e roteirização de prompts.\n",
    "- Com poucos trechos de código, criamos um pipeline de RAG (Retrieval-Augmented Generation).\n",
    "\n",
    "> Próximos passos: experimentar outros modelos, criar novas ferramentas e ajustar prompts para melhorar resultados.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
